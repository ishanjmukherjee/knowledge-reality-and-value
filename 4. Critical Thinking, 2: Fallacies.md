# 4: Critical Thinking, 2: Fallacies
The chapter begins with a list of logical fallacies like one usual in critical thinking textbooks. Some interesting ones:
* **Affirming the Consequent**: The error of arguing, “If A then B. B. Therefore, A”. E.g., suppose you hear that if a person walks on the moon without a space suit, they die (which is true!). You also hear that Uncle Joe has recently died. You infer that Uncle Joe walked on the moon without a space suit. That’s fallacious!
* **Denying the Antecedent**: The error of arguing, “If A then B. ~A. Therefore, ~B”. E.g., “If a person walks on the moon without a space suit, they die. Uncle Joe has not walked on the moon without a spacesuit. Therefore, Uncle Joe has not died.” That’s fallacious!
* **Argumentum ad Ignorantiam** (appeal to ignorance): Concluding that something is the case merely because we don’t know anything to the contrary. Authors sometimes try to lure you into this mistake by writing things like, “There is no reason why X would be true” (hoping that you’ll infer that X isn’t true) or “There is no reason to doubt X” (hoping you’ll infer that X is true).
* **Genetic Fallacy**: Confusing a thing’s origins with its current characteristics. E.g., inferring that all governments are (currently) evil, because governments first originated in gangs of exploiters and conquerors.
* **Tu Quoque**: Responding to a criticism by saying that your accuser is guilty of the same failing. Example: Sue tells Jack that he should stop eating meat. Jack responds by saying that Sue has bought some animal products. This is irrelevant, since the other person’s being guilty of a failing doesn’t show that you are innocent. Unfortunately, this tactic often succeeds in distracting people. (See also “ad hominem” and “red herring”.)

However: "I don’t much like these lists (not even my own). … They direct attention to some problems that occur rarely, while neglecting much more common errors. (Not *all* the traditional fallacies are rare, of course, but several of them are quite rare.) I’m not sure I’ve *ever* seen someone affirm the consequent or deny the antecedent. To the extent that the list identifies genuine errors, most of them are pretty dumb, so you probably don’t need much discussion of them."
***
Huemer then lists other fallacies that are less commonly found in critical thinking textbooks, but often more common in discussions:
* **Anecdotal Evidence**: usually, people don't pick a case randomly. They search for a case that supports their conclusion while ignoring cases that don't. Moreover, random variation and selection effects mean that conclusions from anecdata could be less than robust.
* **Assumptions**: clear those up quickly.
	* Example: "suppose you hear a statistic stating that most murder victims are killed by a family member or someone they knew. You naturally assume that most murders result from domestic disagreements, and that the murders are committed by ordinary people who lost control during an argument with a family member, or something like that. In fact, it turns out that almost everyone who commits a murder has a prior criminal record. Also, the vast majority of the victims are also criminals. (The category “a family member or someone they knew” includes such people as the victim’s drug dealer, the victim’s criminal partner, the victim’s fellow gang members, and so on.) You just *assumed* that these were ordinary people, but the original statistic didn’t say that."
* **Base rate neglect**
* **Cherry picking**
* **Confirmation bias**: "[w]henever you feel inclined to cite some examples supporting belief A, stop and ask yourself whether you can also think of similar examples supporting ~A."
	* Example: "if asked whether liberal politicians are more corrupt than conservative politicians, a conservative would search through his memory for any cases of a liberal doing something corrupt, and he would *not* search through his memory for cases of conservatives being corrupt."
* **Credulity**: news sources aren't reliable because they may be ideologically biased, sensationalist and just have plain lazy editors. Favor academic sources and government reports.
* **Dogmatism and overconfidence**: [calibrate](https://programs.clearerthinking.org/calibrate_your_judgment.html) your judgment.
* **Ideological “cause” judgments**: *X* (eg: the 2008 crash) may have been equally plausibly caused due to *Y* (over-regulation) or *Z* (under-regulation). Don't favor one explanation over the other due to ideological reasons, instead weigh them on their own merits.
* **Oversimplification**
	*  "A tempting simplification would be to say that there are two positions: pro-choice and pro-life (or pro- and anti-abortion). Either fetuses are people and killing them is murder, or fetuses aren’t people and killing them is perfectly fine. But this overlooks the possibility that [for example] late-term fetuses are people but early-term fetuses are not."
* **p-hacking**: This [xkcd comic](https://www.explainxkcd.com/wiki/index.php/882:_Significant) remains the best explanation of p-hacking imo.
* **Speculation**
	* Example: " if the government hadn’t stimulated the economy back in 2009, the recession would have continued much longer."
	* Your premises may not be speculative. 
* **Subjective claims**
	* Examples: "the judgment that political candidate A is “unqualified” for the office; the judgment that it’s worse to be unjustly imprisoned for 5 years than to be prevented from migrating to the country one wants to live in; the judgment that Louis CK’s jokes are “offensive”; etc."
* **Treatment effects vs. selection effects**
	* Are you sure that kids who get after-school academic coaching perform better in tests because of the coaching, and not because they're more driven, wealthy, smarter, etc?
* **Whataboutism**
